{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564d3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.ipynb - execution/backtest using trained model + MCTS\n",
    "# Output: Sharpe ratio only\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from data import MarketFeatureBuilder\n",
    "from spaces import PortfolioEnv\n",
    "from models import ModelConfig, AlphaZeroPortfolioModel\n",
    "from search import MCTS, MCTSConfig\n",
    "\n",
    "\n",
    "class CandidateActionGenerator:\n",
    "    \"\"\"\n",
    "    Discrete action_id -> target weights.\n",
    "    Env will enforce constraints/projection/turnover/costs.\n",
    "    \"\"\"\n",
    "    def __init__(self, env: PortfolioEnv, num_actions: int, max_tilt: float = 0.02, top_k: int = 5, seed: int = 7):\n",
    "        self.env = env\n",
    "        self.num_actions = num_actions\n",
    "        self.max_tilt = max_tilt\n",
    "        self.top_k = top_k\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def __call__(self, action_id: int) -> np.ndarray:\n",
    "        w = self.env.weights.copy()\n",
    "\n",
    "        # Base actions\n",
    "        if action_id == 0:  # hold\n",
    "            return w\n",
    "        if action_id == 1:  # equal-weight\n",
    "            return np.ones(self.env.N) / self.env.N\n",
    "        if action_id == 2:  # de-risk\n",
    "            return 0.8 * w\n",
    "        if action_id == 3:  # re-risk\n",
    "            return 1.2 * w\n",
    "\n",
    "        # Momentum tilt (uses env prices): shift small weight from bottom-K to top-K\n",
    "        t = self.env.t\n",
    "        L = 20\n",
    "        if t - L < 0:\n",
    "            mom = np.zeros(self.env.N)\n",
    "        else:\n",
    "            mom = self.env.logp.iloc[t].to_numpy() - self.env.logp.iloc[t - L].to_numpy()\n",
    "\n",
    "        idx = np.argsort(mom)\n",
    "        bottom = idx[: self.top_k]\n",
    "        top = idx[-self.top_k :]\n",
    "\n",
    "        tilt = float(self.max_tilt * self.rng.uniform(0.25, 1.0))\n",
    "        w_new = w.copy()\n",
    "        w_new[bottom] = np.maximum(0.0, w_new[bottom] - tilt / max(len(bottom), 1))\n",
    "        w_new[top] += tilt / max(len(top), 1)\n",
    "        return w_new\n",
    "\n",
    "\n",
    "def annualized_sharpe(returns: np.ndarray, periods_per_year: int = 252, eps: float = 1e-12) -> float:\n",
    "    returns = returns[np.isfinite(returns)]\n",
    "    if returns.size < 2:\n",
    "        return 0.0\n",
    "    mu = float(np.mean(returns))\n",
    "    sd = float(np.std(returns, ddof=1))\n",
    "    if sd < eps:\n",
    "        return 0.0\n",
    "    return (mu / sd) * np.sqrt(periods_per_year)\n",
    "\n",
    "\n",
    "def run_backtest_sharpe_only(\n",
    "    prices_df,\n",
    "    volumes_df,\n",
    "    checkpoint_path: str = \"checkpoint.pt\",\n",
    "    initial_value: float = 2_000_000.0,\n",
    "    mcts_sims: int = 120,\n",
    "    mcts_depth: int = 3,\n",
    "):\n",
    "    # 1) Compute market features once for the full dataset\n",
    "    builder = MarketFeatureBuilder(prices_df, volumes_df)\n",
    "    market_features_df = builder.batch_features()\n",
    "\n",
    "    # 2) Create environment and reset ONCE (single continuous trajectory)\n",
    "    env = PortfolioEnv(prices_df, market_features_df, initial_value=initial_value)\n",
    "    env.reset()\n",
    "\n",
    "    # 3) Load trained model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "    cfg_dict = ckpt.get(\"model_cfg\", {})\n",
    "    cfg = ModelConfig(**cfg_dict) if cfg_dict else ModelConfig()\n",
    "\n",
    "    model = AlphaZeroPortfolioModel(cfg).to(device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "\n",
    "    # 4) Build action generator and MCTS planner\n",
    "    action_gen = CandidateActionGenerator(env, num_actions=cfg.num_actions)\n",
    "    mcts = MCTS(\n",
    "        model=model,\n",
    "        env=env,\n",
    "        action_generator=action_gen,\n",
    "        cfg=MCTSConfig(num_simulations=mcts_sims, max_depth=mcts_depth),\n",
    "    )\n",
    "\n",
    "    # 5) Iterate through ALL timestamps, collecting realized returns\n",
    "    realized_returns = []\n",
    "    done = False\n",
    "    while not done and env.t < env.T - 1:\n",
    "        w_target = mcts.run()                  # choose action at time t\n",
    "        _, reward, done, _ = env.step(w_target)  # realize return for t->t+1\n",
    "        realized_returns.append(float(reward))\n",
    "\n",
    "    # 6) Compute Sharpe on ALL realized returns and print only that\n",
    "    sharpe = annualized_sharpe(np.array(realized_returns, dtype=float))\n",
    "    print(sharpe)\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# run_backtest_sharpe_only(prices_df, volumes_df, checkpoint_path=\"checkpoint.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
